# GUI and Image Processing Modules
import PySimpleGUI as sg
import io
import os
from PIL import Image

# Prediction
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions
from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# Generating Attention Maps
import re
from tensorflow.keras import backend as K
from tf_keras_vis.utils.model_modifiers import ReplaceToLinear
from tf_keras_vis.utils.scores import CategoricalScore
from tf_keras_vis.gradcam_plus_plus import GradcamPlusPlus
from matplotlib import cm
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import matplotlib
matplotlib.use('TkAgg')



FILE_TYPES = [("JPEG (*.jpg)", ".jpg"),
             ("PNG (*.png)", ".png"),
             ("All files (*.*)", "*,*")]

# TODO: Update documentation to include information about the 
def predict_image(image_path):

    print("Predicting...")

    # Instantiate ResNet50 architecture with ImageNet weights
    model = ResNet50(weights='imagenet')

    # Load image into proper size
    processed_img = image.load_img(image_path, target_size=(224,224))
    x = image.img_to_array(processed_img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)

    preds = model.predict(x)

    # Get the top prediction and confidence
    top_preds = decode_predictions(preds, top=1)[0]
    classification = top_preds[0][1]
    confidence = top_preds[0][2]

    return processed_img, x, model, classification, confidence

def file_to_dict(filepath):
    """
    Converts the imagenet class labels file into a dictionary.
    Text file from https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a#file-imagenet1000_clsidx_to_labels-txt
    """
    imagenet_labels = {}
    file = open(filepath)
    for line in file:
        # Remove apostrophes and white spaces
        line = re.sub("\'", "", line)
        line = line.strip()

        # Split key and value by colon
        key, value = line.split(sep=':')

        # Split and strip labels and turn them into a list
        diff_labels = value.split(',')
        diff_labels.pop() # Drop empty class name at very end

        for i, v in enumerate(diff_labels):
            diff_labels[i] = v.strip()

        # Store a list in each index
        imagenet_labels[key] = diff_labels

    return imagenet_labels

def find_imagenet_index(class_pred, imagenet_labels):
    """
    Finds the proper image net index from the class predicted by ResNet
    """
    for index, classes in imagenet_labels.items():
        if class_pred in classes:
            print(f"Successfully found index! Index = {index}")
            return int(index)

def tf_keras_vis_setup(class_pred, imagenet_labels):
    print("Doing tf-keras-vis setup!")
    replace2linear = ReplaceToLinear()
    imagenet_index = find_imagenet_index(class_pred, imagenet_labels)
    score = CategoricalScore([imagenet_index])

    return replace2linear, score

def get_gradcampp_img(processed_img, 
                      model_input, 
                      model, 
                      class_pred, 
                      imagenet_labels):
    """
    Returns the matplotlib figure of the attention map generated by 
    the GradCam++ visualizer from tf-keras-vis module

    Args:
        processed_img = The resized image; returned by predict_image function
        model_input = Data inputted into the model; returned by predict_image function
                      as x
        model = The CNN model chosen by the user to predict the image
        class_pred = The top class prediction of the model; returned by predict_image
        imagenet_labels (dict) = Dictionary of indices and class labels; returned by file_to_dict
    """

    replace2linear, score = tf_keras_vis_setup(class_pred, imagenet_labels)

    print("Creating GradCAM++ object!")

    # Create GradCAM++ object
    gradcam = GradcamPlusPlus(model,
                              model_modifier=replace2linear,
                              clone=True)

    print("Creating heatmap with GradCAM++!")
    # Generate heatmap with GradCAM++
    cam = gradcam(score,
                  model_input,
                  penultimate_layer=-1)

    print ("Creating matplotlib object!")
    # Create matplotlib plot
    heatmap = np.uint8(cm.jet(cam[0])[..., :3] * 255)
    plt.figure 
    plt.imshow(processed_img)
    plt.imshow(heatmap, cmap='jet', alpha=0.5)
    plt.axis('off')
    
    fig = plt.gcf()

    return fig

# Matplotlib helper function
def draw_figure(canvas, figure):
    figure_canvas_agg = FigureCanvasTkAgg(figure, canvas)
    figure_canvas_agg.draw()
    figure_canvas_agg.get_tk_widget().pack(side='left')
    return figure_canvas_agg

# Before clearing the canvas
def delete_figure_agg(figure_agg):
    figure_agg.get_tk_widget().forget()
    plt.close('all')

def main():

    # Theme 
    sg.theme('Reddit')   

    row1 = [
                sg.Text("Image File"),
                sg.Input(size=(50, 1), enable_events=True, key="-FILE-"),
                sg.FileBrowse(file_types=FILE_TYPES),
                sg.Button("Load Image")
           ]

    col1 = sg.Column(layout=[[sg.Text('', key='-IMAGE-TITLE-TEXT-')],
                             [sg.Image(key="-IMAGE-")]],
                     background_color='white',
                     )

    col2 = sg.Column(layout=[[sg.Canvas(key='-ATTENTION-MAP-CANVAS-', size=(224, 224))]],
                     background_color='white')
    

    # All the stuff inside your window.
    layout = [  
         row1, 

         [col1, col2],

         [sg.Button("Predict", enable_events=True, visible=False, key='-PREDICT-BUTTON-')],

         [sg.Text('', key='-CLASSIFICATION-TEXT-')],
         [sg.Text('', key='-CONFIDENCE-TEXT-')],

         [sg.Button("See Attention Map!", enable_events=True, visible=False, key='-ATTENTION-MAP-BUTTON-')],
    ]

    # Create the Window
    window = sg.Window('Image Viewer', layout, element_justification='c')

    # Empty constant variables for attention map
    processed_img = []
    model_input = []
    model = []
    classification = []
    confidence = []
    fig_canvas_agg = None

    # Event Loop to process "events" and get the "values" of the inputs
    while True:
        event, values = window.read()
        if event == sg.WIN_CLOSED or event == 'Cancel': # if user closes window or clicks cancel
            break
        
        # If canvas is not clear when event loop starts again, clear it
        if fig_canvas_agg:
            delete_figure_agg(fig_canvas_agg)
            
        # Load the image
        if event == "Load Image":
            filename = values["-FILE-"]
            if os.path.exists(filename):
                image = Image.open(values["-FILE-"])
                image.thumbnail((400,400))
                bio = io.BytesIO()
                image.save(bio, format="PNG")
                window["-IMAGE-"].update(data=bio.getvalue())
                window["-PREDICT-BUTTON-"].update(visible=True)
                window["-CLASSIFICATION-TEXT-"].update(value="")
                window["-CONFIDENCE-TEXT-"].update(value="")
                window["-ATTENTION-MAP-BUTTON-"].update(visible=False)
        
        # Predict the image with ResNet
        if event == "-PREDICT-BUTTON-":
            print("Predict button pressed!")
            processed_img, model_input, model, classification, confidence = predict_image(values["-FILE-"])

            # Modify the classification string by removing underscores
            classification = re.sub("_", " ", classification)
            print(classification)

            window["-CLASSIFICATION-TEXT-"].update(value=f"Classification: {classification}")
            window["-CONFIDENCE-TEXT-"].update(value=f"Confidence: {confidence}")
            window["-ATTENTION-MAP-BUTTON-"].update(visible=True)
        
        # Generate the Attention Map
        if event == "-ATTENTION-MAP-BUTTON-":
            print("Generating Attention Map...")

            # Get dictionary
            imagenet_labels = file_to_dict("imagenet_class_labels.txt")
            
            # Generate Gradcam++ Image
            fig = get_gradcampp_img(processed_img, model_input, model, classification, imagenet_labels)

            fig_canvas_agg = draw_figure(window["-ATTENTION-MAP-CANVAS-"].TKCanvas, fig)

            # Change size of canvas
            window["-ATTENTION-MAP-CANVAS-"].set_size=(224, 224)


    window.close()

if __name__ == "__main__":
    main()